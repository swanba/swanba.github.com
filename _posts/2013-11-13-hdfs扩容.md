---
author: Red
encoding: UTF-8
comments: true
date: 2014-03-03 08:00
layout: post
slug: moving-from-wordpress-to-jekyll
title: Hadoop DFS扩容
description: How I decided to move from WordPress to Jekyll. It was fun to build and lots to learn.
categories:
- Miscellaneous
---
#Hadoop DFS扩容



1.增加硬件，在终端用如下命令查看系统device的情况。
    
    #fdisk -l  
能够查看到各个硬盘(光驱、NFS等)的详细情况。具体的参数意义请参考
http://linux.about.com/od/commands/l/blcmdl8_fdisk.htm

2.由于是新增加的设备，需要将其格式化成为我们所需要的文件系统（ext3,ext4等)，
我们通常使用mkfs命令来实现，具体参数意义还请参考
http://linux.about.com/od/commands/l/blcmdl8_mkfs.htm

格式化成为ext3文件系统，命令如下：

    # mkfs -t ext3 -c /dev/devicesnames 
3.这一步主要是将格式化之后的mount到HDFS的数据目录下。
首先，使用vi或者emcas查看我们的Hadoop集群的${HADOOP_HOME}/conf/hdfs-site.xml文件,
其中的dfs.data.dir属性所设定的目录。如果该属性用final标签固定的，那么新增一个目录，
不会被作业配置覆盖（除非namenode-format?)。因而，
我们只将刚刚的设备挂靠到现有的目录下。我们的部分目录如下：/hadoop/dfs/Data

使用如下命令分别将设备mount到各个目录下

    #mount /dev/sdb1  /hadoop/dfs/Data 
    
4. 修改/etc/fstab文件，在文件后面加上如下一行，使得系统启动的时候自动挂载新设备。

    /dev/sdb1  /hadoop/dfs/Data ext3 defaults 1 2

5. 在${HADOOP_HOME}/bin/hadoop 使用dfs -report命令可以马上看到新增的DFS容量。

